# Gastown Operator CI Pipeline
# Kubernetes operator for Gas Town multi-agent orchestration
#
# This is the PRIMARY CI/CD - GitLab/Tekton does all compute.
# GitHub is a read-only storefront that receives code + releases ONLY after tests pass.
#
# Flow:
#   1. validate - lint, manifests, generated code checks
#   2. version  - semantic-release determines version (if any)
#   3. build    - Tekton builds image → INTERNAL registry only
#   4. test     - E2E tests (upgrade + fresh install in test namespaces)
#   5. push     - ONLY after tests pass: push image + helm to GHCR
#   6. publish  - sync code, tag, and release to GitHub
#
# CRITICAL: Nothing is published to GHCR/GitHub until E2E tests pass!
#
# Required CI/CD Variables (set in GitLab project settings):
#   - KUBE_CONFIG: Base64-encoded kubeconfig for olympus-ci namespace
#   - REGISTRY_URL: Container registry URL (e.g., registry.example.com)
#   - GITHUB_TOKEN: PAT with repo scope (for creating releases)
#   - GITHUB_DEPLOY_KEY: SSH deploy key (base64 encoded, for push)
#
# Optional Variables:
#   - TEKTON_NAMESPACE: Override default (olympus-ci)
#
# Secure Files (Settings → CI/CD → Secure Files):
#   - values-internal.yaml: Internal deployment values (DPR registry, etc.)
#     See helm/gastown-operator/values-internal.yaml.example for template

variables:
  # DPR Registry (avoids Docker Hub rate limits)
  DPR_REGISTRY: "dprusocplvjmp01.deepsky.lab:5000"

  # CI Images from DPR
  GO_IMAGE: "${DPR_REGISTRY}/ci-images/golang:1.25"
  GO_LINT_IMAGE: "${DPR_REGISTRY}/ci-images/golangci-lint:v2.7.2"
  KUBECTL_IMAGE: "${DPR_REGISTRY}/ci-images/k8s:1.31.4"
  YAMLLINT_IMAGE: "${DPR_REGISTRY}/ci-images/yamllint:latest"
  NODE_IMAGE: "${DPR_REGISTRY}/library/node:20-alpine"
  ALPINE_GIT_IMAGE: "${DPR_REGISTRY}/library/alpine/git:latest"

  GO_VERSION: "1.25"
  TEKTON_NAMESPACE: "olympus-ci"
  PIPELINE_NAME: "gastown-operator-ci"

stages:
  - validate
  - version
  - build
  - test
  - push
  - publish

# =============================================================================
# Stage: Validate (runs in GitLab, no cluster access needed)
# =============================================================================

lint:go:
  stage: validate
  image: ${GO_LINT_IMAGE}
  script:
    - golangci-lint run --timeout 5m ./...
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH

lint:yaml:
  stage: validate
  image: ${YAMLLINT_IMAGE}
  script:
    - yamllint -d relaxed deploy/ config/
  allow_failure: true
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"

validate:manifests:
  stage: validate
  image: ${GO_IMAGE}
  script:
    - make manifests
    - |
      if ! git diff --exit-code config/; then
        echo "ERROR: Generated manifests are out of date. Run 'make manifests' and commit."
        exit 1
      fi
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH

validate:generate:
  stage: validate
  image: ${GO_IMAGE}
  script:
    - make generate
    - |
      if ! git diff --exit-code api/; then
        echo "ERROR: Generated code is out of date. Run 'make generate' and commit."
        exit 1
      fi
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH

# =============================================================================
# Stage: Version (semantic-release)
# =============================================================================

semantic-release:
  stage: version
  image: ${NODE_IMAGE}
  before_script:
    - apk add --no-cache git
    - npm install -g semantic-release @semantic-release/changelog @semantic-release/git @semantic-release/exec conventional-changelog-conventionalcommits
  script:
    - |
      # Configure git for tagging
      git config user.email "gitlab-ci@gastown.io"
      git config user.name "GitLab CI"

      # Run semantic-release and capture version
      set +e
      OUTPUT=$(npx semantic-release 2>&1)
      EXIT_CODE=$?
      set -e
      echo "$OUTPUT"

      # Extract version if released
      if echo "$OUTPUT" | grep -q "Published release"; then
        VERSION=$(cat VERSION 2>/dev/null || echo "")
        if [ -n "$VERSION" ]; then
          echo "VERSION=$VERSION" >> version.env
          echo "RELEASE_TAG=v$VERSION" >> version.env
          echo "RELEASE_PUBLISHED=true" >> version.env
          echo "New release: v$VERSION"
        fi
      else
        echo "RELEASE_PUBLISHED=false" >> version.env
        echo "No release needed (commits don't trigger release)"
      fi
  artifacts:
    reports:
      dotenv: version.env
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      when: always

# =============================================================================
# Stage: Build (Tekton Pipeline)
# =============================================================================

trigger:tekton:
  stage: build
  image: ${KUBECTL_IMAGE}
  needs:
    - job: semantic-release
      artifacts: true
  before_script:
    - mkdir -p ~/.kube
    - echo "${KUBE_CONFIG}" | base64 -d > ~/.kube/config
    - chmod 600 ~/.kube/config
  script:
    - |
      # Skip if no release was published
      if [ "${RELEASE_PUBLISHED}" != "true" ]; then
        echo "No new version, skipping Tekton build"
        echo "To trigger a release, ensure commits follow conventional commits format:"
        echo "  feat: → minor bump"
        echo "  fix:  → patch bump"
        echo "  feat!: or BREAKING CHANGE: → major bump"
        exit 0
      fi

      echo "========================================"
      echo "  Triggering Tekton Pipeline"
      echo "========================================"
      echo "  Namespace: ${TEKTON_NAMESPACE}"
      echo "  Git URL: ${CI_REPOSITORY_URL}"
      echo "  Git Revision: ${RELEASE_TAG}"
      echo "  Image Tag: ${VERSION}"
      echo "========================================"

      # Create PipelineRun from template with version tag
      cat deploy/tekton/pipelinerun.yaml | \
        sed "s|__GIT_URL__|${CI_REPOSITORY_URL}|g" | \
        sed "s|__GIT_REVISION__|${RELEASE_TAG}|g" | \
        sed "s|__IMAGE_TAG__|${VERSION}|g" | \
        sed "s|__REGISTRY__|${REGISTRY_URL}|g" | \
        kubectl create -f - -n ${TEKTON_NAMESPACE}

      # Get the PipelineRun name
      PIPELINERUN_NAME=$(kubectl get pipelinerun -n ${TEKTON_NAMESPACE} \
        --sort-by='.metadata.creationTimestamp' \
        -l "tekton.dev/pipeline=${PIPELINE_NAME}" \
        -o jsonpath='{.items[-1].metadata.name}')

      echo "Created PipelineRun: ${PIPELINERUN_NAME}"
      echo "PIPELINERUN_NAME=${PIPELINERUN_NAME}" >> tekton.env
  artifacts:
    reports:
      dotenv: tekton.env
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH

monitor:tekton:
  stage: build
  image: ${KUBECTL_IMAGE}
  needs:
    - job: semantic-release
      artifacts: true
    - job: trigger:tekton
      artifacts: true
  before_script:
    - mkdir -p ~/.kube
    - echo "${KUBE_CONFIG}" | base64 -d > ~/.kube/config
    - chmod 600 ~/.kube/config
  script:
    - |
      # Skip if no release was published
      if [ "${RELEASE_PUBLISHED}" != "true" ]; then
        echo "No release triggered, nothing to monitor"
        exit 0
      fi

      echo "Monitoring PipelineRun: ${PIPELINERUN_NAME}"

      # Wait for completion (timeout: 30 minutes)
      TIMEOUT=1800
      ELAPSED=0
      INTERVAL=30

      while [ $ELAPSED -lt $TIMEOUT ]; do
        STATUS=$(kubectl get pipelinerun ${PIPELINERUN_NAME} -n ${TEKTON_NAMESPACE} \
          -o jsonpath='{.status.conditions[?(@.type=="Succeeded")].status}')
        REASON=$(kubectl get pipelinerun ${PIPELINERUN_NAME} -n ${TEKTON_NAMESPACE} \
          -o jsonpath='{.status.conditions[?(@.type=="Succeeded")].reason}')

        echo "[$(date +%H:%M:%S)] Status: ${STATUS} (${REASON})"

        if [ "${STATUS}" = "True" ]; then
          echo ""
          echo "========================================"
          echo "  Tekton Pipeline SUCCEEDED"
          echo "========================================"
          echo ""
          echo "Image built and pushed to internal registry:"
          echo "  - ${REGISTRY_URL}/gastown-operator:${VERSION}"
          echo ""
          echo "Next steps: E2E tests → GHCR push → GitHub release"
          exit 0
        elif [ "${STATUS}" = "False" ]; then
          echo ""
          echo "========================================"
          echo "  Pipeline FAILED: ${REASON}"
          echo "========================================"
          echo ""
          echo "Fetching logs..."
          kubectl get pipelinerun ${PIPELINERUN_NAME} -n ${TEKTON_NAMESPACE} -o yaml
          exit 1
        fi

        sleep $INTERVAL
        ELAPSED=$((ELAPSED + INTERVAL))
      done

      echo "ERROR: Pipeline timed out after ${TIMEOUT}s"
      exit 1
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH

# =============================================================================
# Stage: Push (GHCR - only after E2E tests pass)
# =============================================================================

# Push image from internal registry to GHCR
push:ghcr:
  stage: push
  image:
    name: ${DPR_REGISTRY}/ci-images/skopeo:latest
    entrypoint: [""]  # Override entrypoint (skopeo image sets skopeo as entrypoint)
  needs:
    - job: semantic-release
      artifacts: true
    - job: test:e2e
  before_script:
    - mkdir -p ~/.docker
    # Setup GHCR credentials from CI variable
    - |
      echo "{\"auths\":{\"ghcr.io\":{\"auth\":\"$(echo -n 'boshu2:${GITHUB_TOKEN}' | base64)\"}}}" > ~/.docker/config.json
  script:
    - |
      if [ "${RELEASE_PUBLISHED}" != "true" ]; then
        echo "No release to push"
        exit 0
      fi

      echo "========================================"
      echo "  Pushing Image to GHCR"
      echo "========================================"
      echo "  Source: ${REGISTRY_URL}/gastown-operator:${VERSION}"
      echo "  Target: ghcr.io/boshu2/gastown-operator:${VERSION}"
      echo "========================================"

      # Copy image from internal registry to GHCR
      skopeo copy \
        --src-tls-verify=false \
        docker://${REGISTRY_URL}/gastown-operator:${VERSION} \
        docker://ghcr.io/boshu2/gastown-operator:${VERSION}

      # Also tag as latest
      skopeo copy \
        --src-tls-verify=false \
        docker://${REGISTRY_URL}/gastown-operator:${VERSION} \
        docker://ghcr.io/boshu2/gastown-operator:latest

      echo ""
      echo "Image pushed successfully:"
      echo "  - ghcr.io/boshu2/gastown-operator:${VERSION}"
      echo "  - ghcr.io/boshu2/gastown-operator:latest"
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH

# Push Helm chart to GHCR OCI registry
push:helm:
  stage: push
  image: ${KUBECTL_IMAGE}
  needs:
    - job: semantic-release
      artifacts: true
    - job: push:ghcr
  script:
    - |
      if [ "${RELEASE_PUBLISHED}" != "true" ]; then
        echo "No release to push"
        exit 0
      fi

      echo "========================================"
      echo "  Pushing Helm Chart to GHCR"
      echo "========================================"
      echo "  Version: ${VERSION}"
      echo "  Target: oci://ghcr.io/boshu2/charts"
      echo "========================================"

      # Login to GHCR
      echo "${GITHUB_TOKEN}" | helm registry login ghcr.io -u boshu2 --password-stdin

      # Update Chart.yaml with version
      sed -i "s/^version:.*/version: ${VERSION}/" helm/gastown-operator/Chart.yaml
      sed -i "s/^appVersion:.*/appVersion: \"${VERSION}\"/" helm/gastown-operator/Chart.yaml

      # Package and push
      helm package helm/gastown-operator --destination /tmp/
      helm push /tmp/gastown-operator-${VERSION}.tgz oci://ghcr.io/boshu2/charts

      echo ""
      echo "Helm chart pushed successfully:"
      echo "  oci://ghcr.io/boshu2/charts/gastown-operator:${VERSION}"
      echo ""
      echo "Install with:"
      echo "  helm install gastown-operator oci://ghcr.io/boshu2/charts/gastown-operator --version ${VERSION}"
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH

# =============================================================================
# Stage: Publish (GitHub Sync - only after GHCR push)
# =============================================================================

sync:github:
  stage: publish
  image:
    name: ${ALPINE_GIT_IMAGE}
    entrypoint: [""]  # Override entrypoint (alpine/git sets git as entrypoint)
  needs:
    - job: semantic-release
      artifacts: true
    - job: push:helm
  before_script:
    - apk add --no-cache curl jq openssh-client
    - mkdir -p ~/.ssh
    - echo "${GITHUB_DEPLOY_KEY}" | base64 -d > ~/.ssh/id_ed25519
    - chmod 600 ~/.ssh/id_ed25519
    - ssh-keyscan github.com >> ~/.ssh/known_hosts 2>/dev/null
  script:
    - |
      # Skip if no release was published
      if [ "${RELEASE_PUBLISHED}" != "true" ]; then
        echo "No new version, skipping GitHub sync"
        exit 0
      fi

      echo "========================================"
      echo "  Syncing to GitHub"
      echo "========================================"
      echo "  Version: ${RELEASE_TAG}"
      echo "========================================"

      # Clone and push to GitHub (mirror mode)
      git clone --mirror ${CI_REPOSITORY_URL} /tmp/repo.git
      cd /tmp/repo.git
      git remote add github git@github.com:boshu2/gastown-operator.git || true
      git push github --mirror

      echo "Code synced to https://github.com/boshu2/gastown-operator"

      # Create GitHub Release
      echo "Creating GitHub release ${RELEASE_TAG}..."

      # Build release body
      RELEASE_BODY=$(cat <<EOF
      ## Release ${RELEASE_TAG}

      Built and published by GitLab/Tekton pipeline.

      ### Installation

      **Container Image:**
      \`\`\`bash
      docker pull ghcr.io/boshu2/gastown-operator:${VERSION}
      \`\`\`

      **Helm Chart:**
      \`\`\`bash
      helm install gastown-operator oci://ghcr.io/boshu2/charts/gastown-operator \\
        --version ${VERSION} \\
        -n gastown-system --create-namespace
      \`\`\`

      ### Artifacts

      | Artifact | Location |
      |----------|----------|
      | Image | \`ghcr.io/boshu2/gastown-operator:${VERSION}\` |
      | Helm | \`oci://ghcr.io/boshu2/charts/gastown-operator:${VERSION}\` |

      ---
      *This release was automatically created by GitLab CI after Tekton pipeline passed.*
      EOF
      )

      # Create release via GitHub API
      curl -X POST \
        -H "Authorization: token ${GITHUB_TOKEN}" \
        -H "Accept: application/vnd.github.v3+json" \
        https://api.github.com/repos/boshu2/gastown-operator/releases \
        -d "$(jq -n \
          --arg tag "${RELEASE_TAG}" \
          --arg name "${RELEASE_TAG}" \
          --arg body "${RELEASE_BODY}" \
          '{tag_name: $tag, name: $name, body: $body, draft: false, prerelease: false}')"

      echo ""
      echo "========================================"
      echo "  GitHub Release Created"
      echo "========================================"
      echo "  https://github.com/boshu2/gastown-operator/releases/tag/${RELEASE_TAG}"
      echo "========================================"
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH

# =============================================================================
# Stage: Test (E2E validation before publishing)
# =============================================================================

# Test upgrade path: helm upgrade on existing deployment
deploy:test-upgrade:
  stage: test
  image: ${KUBECTL_IMAGE}
  needs:
    - job: semantic-release
      artifacts: true
    - job: monitor:tekton
  before_script:
    - apk add --no-cache curl
    - mkdir -p ~/.kube
    - echo "${KUBE_CONFIG}" | base64 -d > ~/.kube/config
    - chmod 600 ~/.kube/config
  script:
    - |
      if [ "${RELEASE_PUBLISHED}" != "true" ]; then
        echo "No release to test"
        exit 0
      fi
    - |
      # Check secure file only when we have a release to test
      if [ ! -f "${CI_PROJECT_DIR}/values-internal.yaml" ]; then
        echo "ERROR: values-internal.yaml secure file not found"
        echo "Upload via: GitLab Settings → CI/CD → Secure Files"
        exit 1
      fi

      echo "========================================"
      echo "  Testing: Helm UPGRADE Path"
      echo "========================================"
      echo "  Version: ${VERSION}"
      echo "  Namespace: gastown-test-upgrade"
      echo "========================================"

      # Create test namespace (idempotent)
      kubectl create namespace gastown-test-upgrade --dry-run=client -o yaml | kubectl apply -f -
      kubectl label namespace gastown-test-upgrade --overwrite \
        app.kubernetes.io/managed-by=gitlab-ci \
        environment=test-upgrade

      # Upgrade (or install if first time) - tests the upgrade path
      helm upgrade --install gastown-operator ./helm/gastown-operator \
        --namespace gastown-test-upgrade \
        -f helm/gastown-operator/values.yaml \
        -f ${CI_PROJECT_DIR}/values-internal.yaml \
        --set image.tag="${VERSION}" \
        --wait --timeout 5m

      echo ""
      echo "Waiting for operator to be ready..."
      kubectl wait --for=condition=available deployment/gastown-operator \
        -n gastown-test-upgrade --timeout=120s

      echo ""
      kubectl get pods -n gastown-test-upgrade
      echo ""
      echo "UPGRADE test deployment ready"
  environment:
    name: test-upgrade
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH

# Test fresh install: delete namespace and reinstall from scratch
deploy:test-fresh:
  stage: test
  image: ${KUBECTL_IMAGE}
  needs:
    - job: semantic-release
      artifacts: true
    - job: monitor:tekton
  before_script:
    - apk add --no-cache curl
    - mkdir -p ~/.kube
    - echo "${KUBE_CONFIG}" | base64 -d > ~/.kube/config
    - chmod 600 ~/.kube/config
  script:
    - |
      if [ "${RELEASE_PUBLISHED}" != "true" ]; then
        echo "No release to test"
        exit 0
      fi
    - |
      # Check secure file only when we have a release to test
      if [ ! -f "${CI_PROJECT_DIR}/values-internal.yaml" ]; then
        echo "ERROR: values-internal.yaml secure file not found"
        echo "Upload via: GitLab Settings → CI/CD → Secure Files"
        exit 1
      fi

      echo "========================================"
      echo "  Testing: FRESH Install Path"
      echo "========================================"
      echo "  Version: ${VERSION}"
      echo "  Namespace: gastown-test-fresh"
      echo "========================================"

      # Delete namespace if exists (ensure clean slate)
      echo "Cleaning up any existing deployment..."
      kubectl delete namespace gastown-test-fresh --ignore-not-found --wait=true --timeout=60s || true

      # Wait a moment for cleanup
      sleep 5

      # Create fresh namespace
      kubectl create namespace gastown-test-fresh
      kubectl label namespace gastown-test-fresh \
        app.kubernetes.io/managed-by=gitlab-ci \
        environment=test-fresh

      # Fresh install
      helm install gastown-operator ./helm/gastown-operator \
        --namespace gastown-test-fresh \
        -f helm/gastown-operator/values.yaml \
        -f ${CI_PROJECT_DIR}/values-internal.yaml \
        --set image.tag="${VERSION}" \
        --wait --timeout 5m

      echo ""
      echo "Waiting for operator to be ready..."
      kubectl wait --for=condition=available deployment/gastown-operator \
        -n gastown-test-fresh --timeout=120s

      echo ""
      kubectl get pods -n gastown-test-fresh
      echo ""
      echo "FRESH install test deployment ready"
  environment:
    name: test-fresh
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH

# Run e2e smoke tests against BOTH test deployments
test:e2e:
  stage: test
  image: ${DPR_REGISTRY}/ci-images/k8s:1.31.4
  needs:
    - job: semantic-release
      artifacts: true
    - job: deploy:test-upgrade
    - job: deploy:test-fresh
  before_script:
    - mkdir -p ~/.kube
    - echo "${KUBE_CONFIG}" | base64 -d > ~/.kube/config
    - chmod 600 ~/.kube/config
  script:
    - |
      if [ "${RELEASE_PUBLISHED}" != "true" ]; then
        echo "No release to test"
        exit 0
      fi

      # Run tests against both namespaces
      TEST_NAMESPACES="gastown-test-upgrade gastown-test-fresh"
      OVERALL_PASS=true

      for NS in $TEST_NAMESPACES; do
        echo ""
        echo "========================================"
        echo "  E2E Smoke Tests: ${NS}"
        echo "========================================"
        echo "  Version: ${VERSION}"
        echo "========================================"

        # Test 1: Verify operator is running
        echo ""
        echo "[1/4] Verifying operator pod is running..."
        kubectl get pods -n ${NS} -l app.kubernetes.io/name=gastown-operator
        POD_STATUS=$(kubectl get pods -n ${NS} -l app.kubernetes.io/name=gastown-operator -o jsonpath='{.items[0].status.phase}')
        if [ "$POD_STATUS" != "Running" ]; then
          echo "FAIL: Operator pod not running (status: $POD_STATUS)"
          kubectl logs -n ${NS} -l app.kubernetes.io/name=gastown-operator --tail=50
          OVERALL_PASS=false
          continue
        fi
        echo "PASS: Operator is running"

        # Test 2: Verify CRDs are installed
        echo ""
        echo "[2/4] Verifying CRDs are installed..."
        EXPECTED_CRDS="polecats.gastown.gastown.io rigs.gastown.gastown.io convoys.gastown.gastown.io"
        CRD_PASS=true
        for crd in $EXPECTED_CRDS; do
          if kubectl get crd "$crd" > /dev/null 2>&1; then
            echo "  ✓ $crd"
          else
            echo "  ✗ $crd MISSING"
            CRD_PASS=false
          fi
        done
        if [ "$CRD_PASS" = "false" ]; then
          echo "FAIL: CRDs missing"
          OVERALL_PASS=false
          continue
        fi
        echo "PASS: All CRDs installed"

        # Test 3: Create a test Rig and verify reconciliation
        echo ""
        echo "[3/4] Testing Rig CR reconciliation..."
        RIG_NAME="e2e-test-rig-$(echo $NS | md5sum | cut -c1-6)"
        kubectl apply -f - <<EOF
      apiVersion: gastown.gastown.io/v1alpha1
      kind: Rig
      metadata:
        name: ${RIG_NAME}
        namespace: ${NS}
      spec:
        gitURL: "https://github.com/test/repo.git"
        beadsPrefix: "e2e"
        localPath: "/tmp/e2e-test"
      EOF

        echo "  Waiting for Rig to be processed..."
        sleep 5

        RIG_STATUS=$(kubectl get rig ${RIG_NAME} -n ${NS} -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}' 2>/dev/null || echo "Unknown")
        echo "  Rig status: $RIG_STATUS"

        # Cleanup test Rig
        kubectl delete rig ${RIG_NAME} -n ${NS} --ignore-not-found
        echo "PASS: Rig reconciliation working"

        # Test 4: Check operator logs for errors
        echo ""
        echo "[4/4] Checking operator logs for errors..."
        ERROR_COUNT=$(kubectl logs -n ${NS} -l app.kubernetes.io/name=gastown-operator --tail=100 2>/dev/null | grep -c "ERROR\|FATAL\|panic" || true)
        if [ "$ERROR_COUNT" -gt 0 ]; then
          echo "WARNING: Found $ERROR_COUNT error(s) in operator logs"
          kubectl logs -n ${NS} -l app.kubernetes.io/name=gastown-operator --tail=100 | grep -E "ERROR|FATAL|panic" || true
        else
          echo "PASS: No errors in operator logs"
        fi

        echo ""
        echo "  ✓ ${NS} tests PASSED"
      done

      echo ""
      echo "========================================"
      if [ "$OVERALL_PASS" = "true" ]; then
        echo "  ALL E2E Smoke Tests PASSED"
        echo "========================================"
        echo ""
        echo "Version ${VERSION} validated in both upgrade and fresh install scenarios."
        echo "Ready to publish to GHCR."
      else
        echo "  E2E Smoke Tests FAILED"
        echo "========================================"
        echo ""
        echo "Version ${VERSION} failed validation. NOT publishing to GHCR."
        exit 1
      fi
  environment:
    name: test
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH

# =============================================================================
# Manual Jobs
# =============================================================================

# Deploy to internal cluster using secure file values
# Prerequisites:
#   1. Upload values-internal.yaml to GitLab Secure Files
#   2. Create registry secret in target namespace:
#      kubectl create secret docker-registry dpr-registry-credentials \
#        --docker-server=dprusocplvjmp01.deepsky.lab:5000 \
#        --docker-username=<user> --docker-password=<password> \
#        -n gastown-system
deploy:internal:
  stage: .post
  image: ${KUBECTL_IMAGE}
  needs:
    - job: semantic-release
      artifacts: true
    - job: test:e2e  # Only deploy after e2e tests pass
  before_script:
    - apk add --no-cache curl
    - mkdir -p ~/.kube
    - echo "${KUBE_CONFIG}" | base64 -d > ~/.kube/config
    - chmod 600 ~/.kube/config
  script:
    - |
      if [ "${RELEASE_PUBLISHED}" != "true" ]; then
        echo "No release to deploy"
        exit 0
      fi
    - |
      # Check secure file only when we have a release to deploy
      if [ ! -f "${CI_PROJECT_DIR}/values-internal.yaml" ]; then
        echo "ERROR: values-internal.yaml secure file not found"
        echo "Upload it via: Settings → CI/CD → Secure Files"
        exit 1
      fi

      echo "========================================"
      echo "  Deploying to Internal Cluster"
      echo "========================================"
      echo "  Version: ${VERSION}"
      echo "  Registry: ${REGISTRY_URL}"
      echo "========================================"

      # Install/upgrade using internal values
      helm upgrade --install gastown-operator ./helm/gastown-operator \
        --namespace gastown-system \
        --create-namespace \
        -f helm/gastown-operator/values.yaml \
        -f ${CI_PROJECT_DIR}/values-internal.yaml \
        --set image.tag="${VERSION}" \
        --wait --timeout 5m

      echo ""
      echo "Deployment complete. Verifying..."
      kubectl get deployment -n gastown-system
      kubectl get pods -n gastown-system
  environment:
    name: internal
  when: manual
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH

# Deploy to dev cluster (public GHCR image)
deploy:dev:
  stage: .post
  image: ${KUBECTL_IMAGE}
  needs:
    - job: semantic-release
      artifacts: true
    - job: push:ghcr  # Only available after GHCR push succeeds
  before_script:
    - mkdir -p ~/.kube
    - echo "${KUBE_CONFIG}" | base64 -d > ~/.kube/config
  script:
    - |
      if [ "${RELEASE_PUBLISHED}" != "true" ]; then
        echo "No release to deploy"
        exit 0
      fi

      echo "Deploying to dev cluster..."
      make deploy IMG=ghcr.io/boshu2/gastown-operator:${VERSION}
  environment:
    name: development
  when: manual
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
